/etc/bash_completion.d/yum-utils.bash: line 2: /yum: No such file or directory
BBATH is set to '/mnt/bb_5143c6eb44fdd9d5dd573915de3587aa'
enabled_darshan
DARSHAN_LOG_DIR_PATH=/usr/workspace/iopp/software/iopp/apps/h5bench//darshan-logs/sync_1_4_libdarshan/sync-overwrite
/usr/workspace/iopp/applications/h5bench/build /usr/workspace/iopp/software/iopp/apps/h5bench
2022-10-12 21:14:45,254 h5bench - INFO - Starting h5bench Suite
2022-10-12 21:14:45,286 h5bench - WARNING - Base directory already exists: /p/gpfs1/iopp/temp/h5bench/sync-overwrite
2022-10-12 21:14:45,290 h5bench - INFO - Lustre support not detected
2022-10-12 21:14:45,291 h5bench - DEBUG - LD_LIBRARY_PATH: /usr/WS2/iopp/software/spack-env/h5bench/.spack-env/view/lib:/usr/tce/packages/python/python-3.7.2/lib:/opt/ibm/spectrumcomputing/lsf/10.1.0.10/linux3.10-glibc2.17-ppc64le-csm/lib:/usr/WS2/iopp/software/spack-env/h5bench/.spack-env/view/lib:/usr/tce/packages/cuda/cuda-10.1.243/lib64
2022-10-12 21:14:45,291 h5bench - DEBUG - DYLD_LIBRARY_PATH: 
2022-10-12 21:14:45,291 h5bench - DEBUG - LD_PRELOAD: 
2022-10-12 21:14:45,291 h5bench - INFO - h5bench [overwrite] - Starting
2022-10-12 21:14:45,291 h5bench - INFO - h5bench [overwrite] - DIR: /p/gpfs1/iopp/temp/h5bench/sync-overwrite/ec1f283f/
2022-10-12 21:14:45,293 h5bench - INFO - Parallel setup: jsrun -r 1 -c 4 -a 4 --env LD_PRELOAD=/usr/WS2/iopp/software/spack-env/h5bench/.spack-env/view/lib/libdarshan.so
2022-10-12 21:14:45,294 h5bench - INFO - jsrun -r 1 -c 4 -a 4 --env LD_PRELOAD=/usr/WS2/iopp/software/spack-env/h5bench/.spack-env/view/lib/libdarshan.so h5bench_overwrite /p/gpfs1/iopp/temp/h5bench/sync-overwrite/ec1f283f/h5bench.cfg /p/gpfs1/iopp/temp/h5bench/sync-overwrite/test.h5
2022-10-12 21:14:46,335 h5bench - ERROR - HDF5-DIAG: Error detected in HDF5 (1.13.1) MPI-process 1:
2022-10-12 21:14:46,335 h5bench - ERROR - Check /p/gpfs1/iopp/temp/h5bench/sync-overwrite/ec1f283f/stderr for detailed log
/usr/workspace/iopp/software/iopp/apps/h5bench
logout

------------------------------------------------------------
Sender: LSF System <lsfadmin@lassen710>
Subject: Job 4069461: <sync-overwrite> in cluster <lassen> Done

Job <sync-overwrite> was submitted from host <lassen708> by user <haridev> in cluster <lassen> at Wed Oct 12 21:14:23 2022
Job was executed on host(s) <1*lassen710>, in queue <pbatch>, as user <haridev> in cluster <lassen> at Wed Oct 12 21:14:28 2022
                            <40*lassen584>
</g/g92/haridev> was used as the home directory.
</usr/workspace/iopp/software/iopp/apps/h5bench> was used as the working directory.
Started at Wed Oct 12 21:14:28 2022
Terminated at Wed Oct 12 21:14:47 2022
Results reported at Wed Oct 12 21:14:47 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
/usr/workspace/iopp/software/iopp/apps/h5bench//main.sh /usr/workspace/iopp/software/iopp/apps/h5bench/sync_1_4_libdarshan/sync-overwrite.json sync_1_4_libdarshan 1
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   0.25 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     -
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   19 sec.
    Turnaround time :                            24 sec.

The output (if any) is above this job summary.

